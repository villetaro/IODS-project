# Chapter 3: My data analysis on week 3

```{r} 
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt ", header=T, sep=",")

colnames(alc)

```
# The data has 382 observations and 35 variables after we did the following changes:
 - The variables not used for joining the two data have been combined by averaging  (including the grade variables)
 - 'alc_use' is the average of 'Dalc' and 'Walc'
 - 'high_use' is TRUE if 'alc_use' is higher than 2 and FALSE otherwise

The data is about students alcohol consumption. 

I'm going to conduct an analysis on relationships between high/low alcohol consumption and sex, age and the grades G1, G2 and G3.

My hypothesis is that lower grades lead to higher alcohol consumption. Also I want to see if age or sex has some kind of an effect.

# Drawing the plots and figuring out how my hypothesis begins to look.


```{r, echo=F}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

```{r}
library(ggplot2)
p1 <- ggplot(alc, aes(x = high_use, y = G1, col = sex)) + geom_boxplot() + ylab(" first period grade")

p2 <- ggplot(alc, aes(x = high_use, y = G2, col = sex)) + geom_boxplot() + ylab("second period grade")

p3 <- ggplot(alc, aes(x = high_use, y = G3, col = sex)) + geom_boxplot() + ylab("final grade")

p4 <- ggplot(alc, aes(x = high_use, y = age, col = sex)) + geom_boxplot() + ylab("age")

multiplot(p1, p2, p3, p4, cols = 2)

```

Now lets make a model based on the plots above. I'm trying to explain high usage of alcohol with grades, sex and age. I'm using logistic regression model below.

```{r}

model2 <- glm(high_use ~ G1 + G2 + G3 + sex + age, family = "binomial", data = alc)

summary(model2)

```
Now lets look at the results of model. To me it seems like the p-value is quite low and it indicates that only the variable sex is significant. Age and the grade variables have a much higher p-value which means that they are not that significant at all. 


I decided to leave out G2, G3 and age as they were not significant in the model. Then i made a new model below. Lets look at it again!

```{r}

model3 <- glm(high_use ~ G1 + sex, family = "binomial", data = alc)

summary(model3)

```


```{r}
# define a loss function (average prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)



```
I got the number [1] 0.2801047 out but for some reason the R shows NaN when I knit it.