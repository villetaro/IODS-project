#Chapter 5: Dimensionality reduction techniques

Lets begin the Chapter 5 by loading the data.
```{r, include=FALSE}
library(ggplot2)
library(GGally)
library(MASS)
library(corrplot)
library(tidyverse)
library(plotly)
library(dplyr)
library(FactoMineR)
require(ggplot2)

```

This weeks data contains a large variety of countries. We look for example their life expectancy, GNI and education expectancy.

```{r}
human <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human2.txt", header = T, sep=",")

dim(human)
str(human)

```

We have 155 observations (countries) and 8 different variables.
Next we look at the graphical overview of the data and try to see correlations between the variables.


```{r}
p <- ggpairs(human, mapping = aes(col="blue", alpha=0.3), lower = list(combo = wrap("facethist", bins = 20)))

p
```
There is a lot of significant correlations between the variables. For example Mat.mor - Ado.birth has 0.759 correlation.

```{r}
summary(human)
```

Next I chose a couple of interesting variables and tried to explain them with GNI also known as Gross National Income ($). I chose two variables: Life Expectancy (in years) and Education Expectancy (in years). 

```{r}
p2 <- ggplot(human, aes(x=GNI, y= Life.Exp)) + geom_point(col="deepskyblue1") + geom_smooth( col = "red2")

p2
```

```{r}

model5 <- lm(Life.Exp ~ GNI, human)
summary(model5)
plot(model5,  which=c(1), col = "turquoise2",  lwd = 3)
```
As we see there are quite a few outliers such as Qatar that make the model hard to fit.

```{r}
p3 <- ggplot(human, aes(x=GNI, y= Edu.Exp)) + geom_point(col="red2") + geom_smooth(col = "royalblue1")

p3
```

Next we perform principal component analysis (PCA) on the not standardized human data. 

```{r}
model6 <- lm(Edu.Exp ~ GNI, human)
summary(model6)
plot(model6,  which=c(1), col = "turquoise2",  lwd = 3)
```
This model also suffers a bit as there are those large outliers such as Niger and Qatar.

```{r, warning=FALSE}
# perform principal component analysis (with the SVD method)
pca_human <- prcomp(human)

# draw a biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.5, 1), col = c("black", "red2"), main="Biplot of the first two principal components for the unscaled data")

```

The picture doesn't look very good as we have not standardised the data. A lot of the observations are in the same spot and there seems to be very little correlation. Lets standardise the data and see how the situation changes.

```{r}
human_std <- scale(human)

pca_human11 <- prcomp(human_std)

summary(pca_human11)

```

The data is now standardised and we can draw a new biplot of the first two principal components.

```{r}

biplot(pca_human11, choices = 1:2, cex = c(0.6, 1.2), col = c("black", "red2"),main="Biplot of the first two principal components for the scaled data")


```

Now the arrows are much more clear and we can see those correlations between the variables much better. Also the countries are not anymore in the same spot as they are all over the picture. The biggest correltions against the first two principal components are Labo.Fm and Parli.F. It seems to be a pretty good idea to use these first two components in the biplot and analysis as they have a large part of the variance combined.

Next we go the #part 2 and start it by loading the Tea dataset from Factominer package. It includes 300 observations about how people drink their tea and different habits that are part of the tea drinking. 
```{r}

data("tea")
dim(tea)
str(tea)

```


I decided to drop out some variables as there was 36 of them. It was quite impossible to plot and make a grapical overview with a such variety of different variables.
```{r}
keep <- c("friends", "Tea", "resto", "age_Q", "frequency")

teatimes <- dplyr::select(tea, one_of(keep))

str(teatimes)


```
These are the variables that I decided to keep. Next I drew a multiplot of them where we can see better how they look.

```{r, include= FALSE}
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

```{r}
g1 <- ggplot(teatimes, aes(friends)) + geom_bar() + theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))
g2 <- ggplot(teatimes, aes(Tea)) + geom_bar()+ theme_grey() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))
g3 <- ggplot(teatimes, aes(resto)) + geom_bar() + theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))
g4 <- ggplot(teatimes, aes(age_Q)) + geom_bar()+ theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))
g5 <- ggplot(teatimes, aes(frequency)) + geom_bar()+ theme_grey() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10))

multiplot(g1, g2, g3, g4, g5, cols=3)


```
The most interesting observations are that almost 2/3 of the people drink tea with friends, often not in a restaurant, once or twice a day. The most popular tea is Earl Grey with a large margin. From the age graph we can see that the most answers come from the youngest group which is 15-24 years old people. After that the rest are pretty equal amounts.

Now we do a MCA also known as Multiple Correspondence Analysis. This means that we represent the data in a low-dimensional Euclidean space. It is a counterpart of principal component analysis that we did above.

```{r}
mca <- MCA(X = teatimes, graph=F)

summary(mca)


```

We see the interesting values in v-test where the test-value is 1.96 that we compare against. A lot of times the v-test value is greater than |1.96| which means that a lot them are significant.

The last thing to do is to look at the grapical view of the MCA.

```{r}
plot(mca, invisible=c("ind"), habillage = "quali")

```

We see that the first two dimensions hold the most variance. Dim 1 has 13.55% and Dim 2 has 12.26%. The biggest outliers are green and black as we saw before that the most people in this dataset drink Earl Grey tea. From this we also see that the old people (+60) prefer black tea to others.